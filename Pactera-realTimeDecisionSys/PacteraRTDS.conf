

#============================spark-core配置项================================
#设置spark Streaming 应用程序的名字
spark.commons.appName = realTimeBatch
#spark streaming 每个RDD的分区数（注意配置成kafka topic的分区数）
spark.commons.RDD.num = 80
#spark程序是否优雅的关闭(把接收到的数据处理完毕再关闭spark程序)
spark.commons.gracefully.stop = true
#checkpoint的路径和目录(暂定必填)
spark.commons.checkpoint = hadoop/spark/checkpointfuck
#设置系统打印日记的水平
spark.commons.logLevel= OFF
#设置spark程序的序列化方式(默认java自带)
spark.commons.serializer = org.apache.spark.serializer.KryoSerializer
#spark集群中每个executor中用来存储的内存大小最小比例
spark.commons.storageFraction = 0.2
#spark集群中每个executor中用来shuffle的等操作的内存大小最小比例
spark.commons.shuffle.storageFraction = 0.6
#内存用来存储的比例
spark.commons.memory.storage.fraction = 0.2
#是否开启调整内存存储比例功能
spark.commons.memory.legacy.mode= true

#============================spark-streaming配置项================================
#spark Streaming Dstream调度的时间间隔（单位为秒,默认为5秒）
saprk.streaming.schedulingInterval = 30
# spark Streaming 接收端接收数据的速度（默认为0,其表示不限制）
spark.streaming.receiverMaxRate = 1000
#sparkStreaming.Shuffle.manager的类型(hash,sort)
spark.streaming.shuffle.type = sort
#spark.shuffle缓存大小
spark.streaming.shuffle.file.buffer.size= 64
#spark shuffle read 拉取属于自己数据时重试的次数
spark.streaming.shuffle.fetchData.times = 3
#spark shuffle read 拉取属于自己数据时重试的间隔
spark.streaming.shuffle.fetchData.interval = 5
#executor 与driver的心跳时间
#updatestatebykey分钟数据流中间状态保持的批次数目(与批处理时间的乘积为1800)
spark.streaming.keep.state.min.times = 15
#updatestatebykey预统计小时中间状态保持的批次数目(与批处理时间的乘积为3600)
spark.streaming.keep.state.hour.times = 30
#updatestatebykey预统计小时中间状态保持的批次数目(与批处理时间的乘积为3600)
spark.streaming.keep.state.day.times = 720
spark.streming.executor.heartTime.driver = 10
#stream Media 二期工作统计允许延迟的时间(单位：秒，为分钟的整数倍)
spark.streaming.delay.times.seconds.work =180
#stream Media 三期工作统计允许延迟的时间(单位：秒，为分钟的整数倍)
spark.streaming.delay.times.third.work =180


#============================hbase配置项================================
#连接redis数据库的IP地址
spark.streaming.redis.hosts=192.168.1.126
#连接redis数据库的IP地址
spark.streaming.redis.hosts.port=10060
#输入写入到redis数据库的表的编号(必须设置和库里面表名一样)
spark.streaming.redis.dbindex= streamdetail
#redis数据库一个空闲链接多少时间后关闭
spark.streaming.redis.idle.connect.timeout =12
#redis数据库链接池的最大链接数
spark.streaming.redis.maxTotal.connects = 2000
#redis数据库链接池的最大空闲链接数
spark.streaming.redis.maxIdle.connects = 2000
#redis数据库链接池的最小空闲链接数
spark.streaming.redis.minIdle.connects = 2000
#在获取redis数据库连接的时候检查有效性, 默认false
spark.streaming.redis.checkconnect.isValid  = true
#在释放redis数据库连接的时候检查有效性, 默认false
spark.streaming.redis.checkReturn.isValid  = false
#redis数据库连接耗尽时是否阻塞, false报异常,ture阻塞直到超时, 默认true
spark.streaming.redis.blockWhenExhaustest = true
#redis数据库获取连接时的最大等待毫秒数
spark.streaming.redis.setMaxWaitTime = 100000


#============================kafka的配置项================================
#======================kafka-config==============================
#直接读取非延迟kafka channel 数据的topic
spark.streaming.realTime.kafkaTopics = tpcstreammonitor
#直接读取kafka channel 数据的brokers
spark.streaming.kafkaBrokers = 172.16.16.23:9092,172.16.16.24:9092,172.16.16.25:9092
#直接读取kafka channel 数据的偏移量的策略
spark.streaming.kafka.offsets = smallest



#======================业务相关-Config==============================
#保留无新数据更新状态的批次数目(默认5次)
sparkConfig.keepState.times = 10
#本机hadoop 的hdfs配置文件目录
sparkConfig.hadoop.hdfs.core-site.xml.path =/usr/local/hadoop/etc/hadoop/core-site.xml
#最新的offset文件保存在hdfs上的前缀(注意不能配"/")
sparkConfig.offset.hdfs.path.suffix = hdfs://mycluster:8020/hadoop/data
#offset文件定时保存在hdfs上的前缀(注意不能配"/")
sparkConfig.offset.hdfs.path.suffix.copy = hdfs://mycluster:8020/hadoop/data/hdfsData
#读取由Streaming产生的分钟数据RDD文件(第一次运行时为空)
sparkConfig.readHdfsData.min.RDD.Path =hdfs://115.231.107.186/tmp/checkpointTest/PacteraMin/
#读取由Streaming产生的小时数据RDD文件(第一次运行时为空)
sparkConfig.readHdfsData.hour.RDD.Path =hdfs://115.231.107.186/tmp/checkpointTest/PacteraHour/
#读取由Streaming产生的天数据RDD文件(第一次运行时为空)
sparkConfig.readHdfsData.day.RDD.Path =hdfs://115.231.107.186/tmp/checkpointTest/PacteraDay/
#yarn上面优雅关闭的替代手段
sparkConfig.gracefully.stop.path = hdfs://mycluster:8020/hadoop/data/